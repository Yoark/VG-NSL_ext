{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'test']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"##test\".split('##')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"testtest\".replace(\"test\", \"\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: token list 1 (whole words), token list 2 (word pieces)\n",
    "# output: list of tuples of indexes of word pieces coresponding to each whole word.\n",
    "from collections import defaultdict\n",
    "def get_whole_word(whole, piece):\n",
    "    inds = []\n",
    "    piece_ind = 0\n",
    "    for i, word in enumerate(whole):\n",
    "        curr_word = word\n",
    "        num_chars = len(word)\n",
    "        ind = []\n",
    "        while num_chars != 0:\n",
    "            if piece[piece_ind].startswith(\"##\"):\n",
    "                sub = piece[piece_ind][2:]\n",
    "                num_chars -= len(sub)\n",
    "                ind.append(piece_ind)\n",
    "                piece_ind += 1\n",
    "            else:\n",
    "                num_chars -= len(piece[piece_ind])\n",
    "                ind.append(piece_ind)\n",
    "                piece_ind += 1\n",
    "        inds.append(ind)\n",
    "    return inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Aboy', 'is', 'ahead', 'alove'],\n",
       " ['A', '##boy', 'is', 'a', '##hea', '##d', 'a', '##lov', '##e'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole = \"Aboy is ahead alove\".split()\n",
    "piece = \"A ##boy is a ##hea ##d a ##lov ##e\".split()\n",
    "whole, piece\n",
    "#an = ['[CLS]', 'a', 'small', 'bird', 'sitting', 'on', 'the', 'back', 'of', 'a', 'blue', 'chair', '.', '[SEP]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_whole_word(whole, piece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1], [2], [3, 4, 5], [6, 7, 8]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: token list 1 (whole words), token list 2 (word pieces)\n",
    "# output: list of tuples of indexes of word pieces coresponding to each whole word.\n",
    "from collections import defaultdict\n",
    "def get_whole_word(whole, piece):\n",
    "    ind = defaultdict(list)\n",
    "    piece_ind = 0\n",
    "    for i in range(len(whole)):\n",
    "        print(1)\n",
    "        curr_word = whole[i]\n",
    "        if curr_word == piece[piece_ind]:\n",
    "            ind[whole[i]].append(piece_ind)\n",
    "            print(f'i, j: {i, piece_ind}')\n",
    "            piece_ind += 1\n",
    "            continue\n",
    "        #piece_ind += 1    \n",
    "        if piece[piece_ind].startswith(\"##\"):\n",
    "            combine = True\n",
    "            ind[whole[i]].append(piece_ind-1)\n",
    "            ind[whole[i]].append(piece_ind)\n",
    "            sub = piece[piece_ind].split('##')[1]\n",
    "            curr_word = whole[i]\n",
    "            curr_word = curr_word.replace(piece[piece_ind-1], '', 1)\n",
    "            curr_word = curr_word.replace(sub, '', 1)\n",
    "            piece_ind += 1\n",
    "            while combine == True:\n",
    "                if piece_ind == len(piece):\n",
    "                    return ind\n",
    "                if piece[piece_ind].startswith(\"##\"):                    \n",
    "                    sub = piece[piece_ind].split('##')[1]\n",
    "                    if curr_word == '':\n",
    "                        break\n",
    "                    else:\n",
    "                        ind[whole[i]].append(piece_ind)\n",
    "                        curr_word = curr_word.replace(sub, '', 1)\n",
    "                        print(curr_word, sub)\n",
    "                    piece_ind += 1\n",
    "                elif not piece[piece_ind].startswith(\"##\"):\n",
    "                    combine = False\n",
    "                    break\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'Aboy': [0, 1],\n",
       "             'is': [2],\n",
       "             'ahead': [3, 4, 5],\n",
       "             'alove': [6, 7, 8]})"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt =list(test.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1], [2], [3, 4, 5], [6, 7, 8]]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.zeros(len(piece), len(whole))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(whole)):\n",
    "    t[tt[i], i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 2 at dim 1 (got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-901634544a78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 2 at dim 1 (got 1)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.ones(2,3,4)\n",
    "t2 = torch.ones(2,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 4., 4., 4., 4.],\n",
       "         [4., 4., 4., 4., 4.],\n",
       "         [4., 4., 4., 4., 4.]],\n",
       "\n",
       "        [[4., 4., 4., 4., 4.],\n",
       "         [4., 4., 4., 4., 4.],\n",
       "         [4., 4., 4., 4., 4.]]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.matmul(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (1, 5)\n",
      "1 (2, 6)\n",
      "2 (3, 7)\n",
      "3 (4, 8)\n",
      "4 (5, 9)\n"
     ]
    }
   ],
   "source": [
    "t1 = [1,2,3,4,5]\n",
    "t2 = [5,6,7,8,9]\n",
    "for i, a in enumerate(zip(t1, t2)):\n",
    "    print(i, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
