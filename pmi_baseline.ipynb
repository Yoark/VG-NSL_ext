{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "# implement PMI baseline for unsupervised parsing tree generation\n",
    "train = None\n",
    "val = None\n",
    "test = None\n",
    "linux_data_path = \"/home/zijiao/work/data/mscoco/train_caps.txt\"\n",
    "mac_data_path = \"/Users/zijiaoyang/Documents/data/mscoco/train_caps.txt\"\n",
    "file_path = \"/Users/zijiaoyang/Documents/data/mscoco\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 413915 captions so image is supposed to be 82783 \n",
    "with open(mac_data_path, 'r') as f:\n",
    "    words_doc = []\n",
    "    bigram_doc = []\n",
    "    sentences = []\n",
    "    for line in f:\n",
    "        #sentence = tokenizer(line.strip())\n",
    "        #sentence = ['<s>'] + sentence + ['</s>']\n",
    "        sentence = line.strip().lower().split()\n",
    "        sentences.append(sentence)\n",
    "        bigram_doc.extend(list(zip(sentence, sentence[1:])))\n",
    "        words_doc.extend(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Simple vocabulary wrapper.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.idx = 0\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.word2idx[word] = self.idx\n",
    "            self.idx2word[self.idx] = word\n",
    "            self.idx += 1\n",
    "\n",
    "    def __call__(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            return self.word2idx['<unk>']\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)\n",
    "\n",
    "import pickle\n",
    "with open(\"../data/mscoco/vocab.pkl\", 'rb') as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute dicts\n",
    "word2count = defaultdict(lambda: 0)\n",
    "bigram2count = defaultdict(lambda: 0)\n",
    "for word in words_doc:\n",
    "    if vocab(word) == '<unk>':\n",
    "        word2count[vocab('<unk>')] += 1\n",
    "    word2count[vocab(word)] += 1\n",
    "for w1, w2 in bigram_doc:\n",
    "    if vocab(w1) == '<unk>' or vocab(w2) == '<unk>':\n",
    "        word2count[vocab('<unk>'), vocab('<unk>')] += 1\n",
    "    bigram2count[(vocab(w1), vocab(w2))] += 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compute probs\n",
    "total_wdcounts = reduce(lambda a, b: a+b, list(word2count.values()))\n",
    "p_uni = {word: count/total_wdcounts for word, count in word2count.items()}\n",
    "total_bicounts = reduce(lambda a, b: a+b, list(bigram2count.values()))\n",
    "p_bi = {bigram: count/total_bicounts for bigram, count in bigram2count.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pmi(word1, word2, p_uni=p_uni, p_bi=p_bi, smooth=.7):\n",
    "    \"\"\"\n",
    "    Compute Negtive pointwise mutual information\n",
    "    # add 1 smoothing\n",
    "    \"\"\"\n",
    "    word1, word2 = vocab(word1), vocab(word2)\n",
    "    return np.minimum(np.log(p_bi.get((word1, word2), 0)+smooth/(p_uni.get(word1, 0) + smooth) * (p_uni.get(word2, 0) +smooth)), 0)\n",
    "\n",
    "def parse(distance, left, right):\n",
    "    \"\"\"\n",
    "    Compute the paring boundary based on given syntactic distance\n",
    "    \n",
    "    Input: distances computed for a sentence,\n",
    "    left and right are boundaries\n",
    "    :return: boundaries\n",
    "    \"\"\"\n",
    "    if left == right:\n",
    "        return []\n",
    "    #print(left, right)\n",
    "    p = left + np.argmax(distance[left: right])\n",
    "    return [(left, right)] + parse(distance, left, p) + parse(distance, p+1, right)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute spans for tree in data_path\n",
    "def compute_npmi(data_path, sm=.7):\n",
    "    with open(data_path) as f:\n",
    "        sent_distances = []\n",
    "        for line in f:\n",
    "            # original code line.strip().lower().split() we used tokenizer here\n",
    "            #sentence = tokenizer(line.strip().lower())\n",
    "            sentence = line.strip().lower().split()\n",
    "            bis = zip(sentence, sentence[1:])\n",
    "            # Compute negative pointwise mutual info\n",
    "            dist = [pmi(word1, word2,smooth=sm) for word1, word2 in bis]\n",
    "            sent_distances.append(dist)\n",
    "            #sent_distances.append((sentence, dist))\n",
    "    return sent_distances\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%p\n"
    }
   },
   "outputs": [],
   "source": [
    "# generate test dists\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "data_path = '/Users/zijiaoyang/Documents/data/mscoco/'\n",
    "bras = []\n",
    "for sm in np.linspace(0.1, 5, num=20):\n",
    "    sent_distances = compute_npmi(os.path.join(data_path, 'test_caps.txt'), sm=sm)\n",
    "    brackets = [parse(dis, 0, len(dis)-1) for dis in sent_distances]\n",
    "    bras.append((sm, brackets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: compute f1 score for pmi baseline\n",
    "# TODO: solve possible OOV problem, partly solved\n",
    "# TODO: make data preprocssing same as original code, so fair compare can be made: DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sm is 0.10\n",
      "F1 score: 32.20, precision: 29.29, recall: 35.75\n",
      "sm is 0.36\n",
      "F1 score: 32.23, precision: 29.31, recall: 35.78\n",
      "sm is 0.62\n",
      "F1 score: 32.23, precision: 29.32, recall: 35.78\n",
      "sm is 0.87\n",
      "F1 score: 32.34, precision: 29.42, recall: 35.90\n",
      "sm is 1.13\n",
      "F1 score: 34.68, precision: 31.55, recall: 38.50\n",
      "sm is 1.39\n",
      "F1 score: 34.68, precision: 31.55, recall: 38.50\n",
      "sm is 1.65\n",
      "F1 score: 34.68, precision: 31.55, recall: 38.50\n",
      "sm is 1.91\n",
      "F1 score: 34.68, precision: 31.55, recall: 38.50\n",
      "sm is 2.16\n",
      "F1 score: 34.68, precision: 31.55, recall: 38.50\n",
      "sm is 2.42\n",
      "F1 score: 34.68, precision: 31.55, recall: 38.50\n",
      "sm is 2.68\n",
      "F1 score: 34.68, precision: 31.55, recall: 38.50\n",
      "sm is 2.94\n",
      "F1 score: 34.68, precision: 31.55, recall: 38.50\n",
      "sm is 3.19\n",
      "F1 score: 34.68, precision: 31.55, recall: 38.50\n",
      "sm is 3.45\n",
      "F1 score: 34.68, precision: 31.55, recall: 38.50\n",
      "sm is 3.71\n",
      "F1 score: 34.68, precision: 31.55, recall: 38.50\n",
      "sm is 3.97\n",
      "F1 score: 34.68, precision: 31.55, recall: 38.50\n",
      "sm is 4.23\n",
      "F1 score: 34.68, precision: 31.55, recall: 38.50\n",
      "sm is 4.48\n",
      "F1 score: 34.68, precision: 31.55, recall: 38.50\n",
      "sm is 4.74\n",
      "F1 score: 34.68, precision: 31.55, recall: 38.50\n",
      "sm is 5.00\n",
      "F1 score: 34.68, precision: 31.55, recall: 38.50\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "#from evaluation import test_trees\n",
    "#from vocab import Vocabulary\n",
    "\n",
    "def extract_spans(tree):\n",
    "    answer = list()\n",
    "    stack = list()\n",
    "    items = tree.split()\n",
    "    curr_index = 0\n",
    "    for item in items:\n",
    "        if item == ')':\n",
    "            pos = -1\n",
    "            right_margin = stack[pos][1]\n",
    "            left_margin = None\n",
    "            while stack[pos] != '(':\n",
    "                left_margin = stack[pos][0]\n",
    "                pos -= 1\n",
    "            assert left_margin is not None\n",
    "            assert right_margin is not None\n",
    "            stack = stack[:pos] + [(left_margin, right_margin)]\n",
    "            answer.append((left_margin, right_margin))\n",
    "        elif item == '(':\n",
    "            stack.append(item)\n",
    "        else:\n",
    "            stack.append((curr_index, curr_index))\n",
    "            curr_index += 1\n",
    "    return answer\n",
    "\n",
    "\n",
    "def extract_statistics(gold_tree_spans, produced_tree_spans):\n",
    "    gold_tree_spans = set(gold_tree_spans)\n",
    "    produced_tree_spans = set(produced_tree_spans)\n",
    "    precision_cnt = sum(list(map(lambda span: 1.0 if span in gold_tree_spans else 0.0, produced_tree_spans)))\n",
    "    recall_cnt = sum(list(map(lambda span: 1.0 if span in produced_tree_spans else 0.0, gold_tree_spans)))\n",
    "    precision_denom = len(produced_tree_spans)\n",
    "    recall_denom = len(gold_tree_spans)\n",
    "    return precision_cnt, precision_denom, recall_cnt, recall_denom\n",
    "\n",
    "\n",
    "def f1_score(produced_trees, gold_trees):\n",
    "    gold_trees = list(map(lambda tree: extract_spans(tree), gold_trees))\n",
    "    #produced_trees = list(map(lambda tree: extract_spans(tree), produced_trees))\n",
    "    # TODO: get spans from pmi baseline, $$DONE\n",
    "    assert len(produced_trees) == len(gold_trees)\n",
    "    precision_cnt, precision_denom, recall_cnt, recall_denom = 0, 0, 0, 0\n",
    "    for i, item in enumerate(produced_trees):\n",
    "        pc, pd, rc, rd = extract_statistics(gold_trees[i], item)\n",
    "        precision_cnt += pc\n",
    "        precision_denom += pd\n",
    "        recall_cnt += rc\n",
    "        recall_denom += rd\n",
    "    precision = float(precision_cnt) / precision_denom * 100.0\n",
    "    recall = float(recall_cnt) / recall_denom * 100.0\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    return f1, precision, recall\n",
    "\n",
    "\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--candidate', type=str, required=False,\n",
    "#                     help='model path to evaluate')\n",
    "# parser.add_argument('--produced_path', required=True, default='./',\n",
    "#                     help='the path to produced_tree_spans')\n",
    "# args = parser.parse_args()\n",
    "# TODO: change path: Done\n",
    "#ground_truth = [line.strip() for line in open(\n",
    "#    os.path.join('/home/zijiao/work/data/mscoco/', 'test_ground-truth.txt'))]\n",
    "ground_truth = [line.strip() for line in open(\n",
    "    os.path.join('/Users/zijiaoyang/Documents/data/mscoco/', 'test_ground-truth.txt'))]\n",
    "\n",
    "# import pickle\n",
    "# with open(args.produced_path, 'rb') as f:\n",
    "#     trees = pickle.load(f)\n",
    "#trees = [line.strip() for line in open(os.path.join('/home/zijiao/work/VGSNLextend/trees.txt'))]\n",
    "for sm, trees in bras:\n",
    "    f1, precision, recall =  f1_score(trees, ground_truth)\n",
    "#print('Model:', args.candidate)\n",
    "    print(f'sm is {sm:.2f}')\n",
    "    print(f'F1 score: {f1:.2f}, precision: {precision:.2f}, recall: {recall:.2f}')\n",
    "# TODO: check if it works, it worked......\n",
    "# TODO: generate tree file for test:DONE\n",
    "# ! change vocab to default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/zijiaoyang/Documents/data/mscoco/test_caps.txt', 'r') as f:\n",
    "    sents = []\n",
    "    for line in f:\n",
    "        sents.append(line.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'man riding a motor bike on a dirt road on the countryside .'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
